{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMwfzh3zOvd3jgy6rl8S90k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Git2723122/y4-dissertation/blob/main/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Manually installs keras-tuner (not built into colab).\n",
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_6CLA1HerHJ",
        "outputId": "6372a160-ebd6-4b55-bfdb-39f5cb01f34c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import normalize, to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.losses import CategoricalFocalCrossentropy, CategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras_tuner as kt\n",
        "from keras_tuner import RandomSearch\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import gc\n",
        "save = set(globals().keys())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f2cgSqIZker7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c5CuE_oJYeVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create access variables for relevant dataset directories.\n",
        "image_folder_dir = \"/content/drive/MyDrive/HAM10000_images/\"\n",
        "metadata_file_dir = \"/content/drive/MyDrive/HAM10000_metadata.csv\"\n",
        "\n",
        "#Convert metadata csv into a pandas dataframe for manipulation.\n",
        "metadata = pd.read_csv(metadata_file_dir)\n",
        "\n",
        "#This should print the first 5 metadata rows, otherwise something is wrong.\n",
        "print(metadata.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki4a_G2zDPi8",
        "outputId": "fc4a783a-8c69-40a6-d798-6b5787c0fbe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     lesion_id      image_id   dx dx_type   age   sex localization\n",
            "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
            "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
            "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
            "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
            "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add a new column to the dataframe containing numerical labels of each classification (the CNN requires numerical outputs)\n",
        "text_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
        "labels = {label: i for i, label in enumerate(text_labels)}\n",
        "metadata[\"label\"] = metadata[\"dx\"].map(labels)\n",
        "\n",
        "#Through the metadata file, finds the directory for each image and accesses it.\n",
        "#Performs normalization on each image's size and pixel values\n",
        "#Appends each normalized images data to list X and its numerical label to list y\n",
        "X, y = [],[]\n",
        "\n",
        "def process_image(image_id):\n",
        "  #Image Access\n",
        "  image_dir=os.path.join(image_folder_dir, image_id + \".jpg\")\n",
        "  image = cv2.imread(image_dir)\n",
        "  if image is None:\n",
        "    return None, None\n",
        "  #Normalize\n",
        "  image = cv2.resize(image, (75,100))\n",
        "  image = image/255.0\n",
        "  #Append relevant info\n",
        "  return image\n",
        "\n",
        "#Processes each image and provides a progress bar. Uses multiple threads for speed.\n",
        "with ThreadPoolExecutor(max_workers=16) as executor:\n",
        "  results = list(tqdm(executor.map(process_image, metadata[\"image_id\"]), total=len(metadata)))\n",
        "\n",
        "#Prepare the samples and their labels and convert them into NumPy arrays for Keras.\n",
        "for i, (image) in enumerate(results):\n",
        "  if image is not None:\n",
        "    X.append(image)\n",
        "    y.append(metadata[\"label\"].iloc[i])\n",
        "\n",
        "X = np.array(X, dtype=np.float32)\n",
        "y_initial = np.array(y, dtype=np.int32)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtOPoOwqy0T6",
        "outputId": "66a534c9-b874-4ecc-cb4e-01d31c1d3da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10015/10015 [08:04<00:00, 20.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the random undersampler. Undersample only the majority (nv) to 1800\n",
        "underSampler = RandomUnderSampler(sampling_strategy={5:1800}, random_state=42)\n",
        "#Reshape and undersample then revert shape.\n",
        "X_undersampled,y_undersampled = underSampler.fit_resample(X.reshape(len(X), -1), y_initial)\n",
        "X_undersampled = X_undersampled.reshape(-1,100,75,3)\n",
        "unique, counts = np.unique(y_undersampled, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4Q5917NFMn2",
        "outputId": "b59777e2-4457-4c50-9c78-faaf948c6d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 327, 1: 514, 2: 1099, 3: 115, 4: 1113, 5: 1800, 6: 142}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the data augmentor and its possible transformations.\n",
        "generator = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    zoom_range = [0.75,1.25],\n",
        "    fill_mode='nearest',\n",
        "    )\n",
        "#Collect the number of samples in each classes\n",
        "class_counts = np.unique(y_undersampled, return_counts=True)[1]\n",
        "class_counts_dict = {i: count for i, count in enumerate(class_counts)}\n",
        "#Set the threshold for classes to augment.\n",
        "target_count = 600\n",
        "X_augmented = []\n",
        "y_augmented = []\n",
        "for label, count in class_counts_dict.items():\n",
        "  #Check if the number of samples in the class is below the maximum\n",
        "  if count < target_count:\n",
        "    diff = target_count - count\n",
        "    indices = np.where(y_initial == label)[0]\n",
        "    for i in range(diff):\n",
        "      image_to_augment_index = np.random.choice(indices)\n",
        "      image_to_augment = X[image_to_augment_index]\n",
        "      image_to_augment = np.expand_dims(image_to_augment, axis=0)\n",
        "      augmented_image = generator.flow(image_to_augment, batch_size=1)[0][0]\n",
        "      X_augmented.append(augmented_image)\n",
        "      y_augmented.append(label)\n",
        "#Convert the lists into arrays and join them with their preexisting arrays.\n",
        "X_augmented = np.array(X_augmented)\n",
        "y_augmented = np.array(y_augmented)\n",
        "\n",
        "X_new = np.concatenate((X_undersampled, X_augmented), axis=0)\n",
        "y_new = np.concatenate((y_undersampled, y_augmented), axis=0)\n",
        "\n",
        "new_counts = np.unique(y_new, return_counts=True)[1]\n",
        "print(new_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iZpZntSyrnd",
        "outputId": "acf065ea-9e30-44cc-f944-739583ce358b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 600  600 1099  600 1113 1800  600]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the SMOTE oversampler. Oversample all but nv to 1800.\n",
        "overSampler = SMOTE(sampling_strategy={0: 1800, 1: 1800, 2: 1800, 3: 1800, 4: 1800, 6: 1800}, random_state=42)\n",
        "#Reshape and oversample then revert shape.\n",
        "X_oversampled, y_oversampled = overSampler.fit_resample(X_new.reshape(len(X_new), -1), y_new)\n",
        "X_oversampled = X_oversampled.reshape(-1, 100, 75, 3)\n",
        "unique, counts = np.unique(y_oversampled, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr6MzAvwKRj-",
        "outputId": "6a1ebb73-347d-4b6c-fd0d-3a91f894712c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 1800, 1: 1800, 2: 1800, 3: 1800, 4: 1800, 5: 1800, 6: 1800}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the balanced dataset.\n",
        "X_ready, y_ready = shuffle(X_oversampled, y_oversampled, random_state=42)\n",
        "print(f\"Training Set: {X_ready.shape}, Test Set: {y_ready.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LhXYt6uOdA5",
        "outputId": "df176f70-51aa-4ef8-c545-426785140f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set: (12600, 100, 75, 3), Test Set: (12600,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete all variables that arent related to libraries or built in functions and not in the whitelist.\n",
        "#Saves a significant amount of RAM.\n",
        "allvars = set(globals().keys())\n",
        "whitelist = {\"X_ready\",\"y_ready\",\"labels\"}\n",
        "blacklist = allvars-save\n",
        "print(blacklist)\n",
        "for var in blacklist:\n",
        "  if var not in whitelist:\n",
        "    del globals()[var]\n",
        "\n",
        "gc.collect()\n",
        "print(globals().keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNkcKoKVpivA",
        "outputId": "8b319073-6553-4b4b-908c-d5ce6eae5775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'counts', '_i13', 'count', 'image_folder_dir', 'i', 'executor', '_i10', 'new_counts', 'label', 'metadata', 'process_image', 'y', 'X_augmented', 'labels', 'class_counts', 'y_oversampled', '_i11', '_i9', '_i5', '_i3', 'X', '_i8', '_i6', 'overSampler', 'X_new', 'X_oversampled', 'y_ready', 'text_labels', 'metadata_file_dir', 'save', '_i7', 'y_initial', 'y_new', '_i14', 'image_to_augment', 'unique', 'y_undersampled', 'augmented_image', 'y_augmented', 'drive', 'X_undersampled', '_i12', 'underSampler', 'generator', 'diff', 'image', '_i4', '_i15', 'indices', 'target_count', 'image_to_augment_index', 'X_ready', 'class_counts_dict', 'results', '_i16'}\n",
            "dict_keys(['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__builtin__', '__builtins__', '_ih', '_oh', '_dh', 'In', 'Out', 'get_ipython', 'exit', 'quit', '_', '__', '___', '_i', '_ii', '_iii', '_i1', '_exit_code', '_i2', 'tf', 'np', 'pd', 'os', 'sys', 'Sequential', 'Model', 'Dense', 'Dropout', 'Activation', 'Flatten', 'Conv2D', 'MaxPooling2D', 'Input', 'GlobalAveragePooling2D', 'mnist', 'normalize', 'to_categorical', 'Adam', 'ImageDataGenerator', 'ResNet50', 'CategoricalFocalCrossentropy', 'CategoricalCrossentropy', 'EarlyStopping', 'kt', 'RandomSearch', 'LinearSVC', 'classification_report', 'accuracy_score', 'StandardScaler', 'LogisticRegression', 'KNeighborsClassifier', 'train_test_split', 'compute_class_weight', 'shuffle', 'cv2', 'tqdm', 'ThreadPoolExecutor', 'RandomUnderSampler', 'SMOTE', 'gc', 'labels', 'X_ready', 'y_ready', 'allvars', 'whitelist', 'blacklist', 'var'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#One hot encode the labels, representing each as a 0 or 1 in a vector.\n",
        "y = to_categorical(y_ready, len(labels))\n",
        "\n",
        "#Split the dataset into 80% training 20% testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_ready, y, test_size = 0.2, stratify=y, random_state=42)\n",
        "print(f\"Training Set: {x_train.shape}, Test Set: {x_test.shape}\")\n",
        "print(f\"Training Labels: {y_train.shape}, Test Labels: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjZUsTd5vhZ4",
        "outputId": "b442b102-f097-4ff6-9ce9-8ede2fbde445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set: (10080, 100, 75, 3), Test Set: (2520, 100, 75, 3)\n",
            "Training Labels: (10080, 7), Test Labels: (2520, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping=EarlyStopping(monitor='val_loss',patience=5,verbose=1, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "2Drj9uG0X6Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the model and set all potential hyperparam values incl. layer count\n",
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(100,75,3)))\n",
        "  model.add(Conv2D(filters=hp.Int('filters_base', 16, 128, step=16), kernel_size=(3,3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(rate=hp.Float('rate_base', 0.1, 0.4, step=0.1)))\n",
        "\n",
        "  num_layers = hp.Int('num_layers', 1, 4)\n",
        "  for i in range(num_layers):\n",
        "    model.add(Conv2D(filters=hp.Int(f'F_{i}', 32, 256, step=32), kernel_size=(3,3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(rate=hp.Float(f'R_{i}', 0.1, 0.4, step=0.1)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  for i in range(hp.Int('num_dense_layers', 1,2)):\n",
        "    model.add(Dense(units=hp.Int(f'neurons_{i}',64,256,step=64), activation='relu'))\n",
        "    model.add(Dropout(rate=hp.Float(f'rate_dense_{i}', 0.1, 0.4, step=0.1)))\n",
        "\n",
        "  model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-3, 1e-4, 1e-5])),\n",
        "              loss=CategoricalFocalCrossentropy(label_smoothing=0.1),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "#Create the RandomSearcher\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective=kt.Objective('val_accuracy', direction='max'),\n",
        "    max_trials=15,\n",
        "    directory='/content/tuning_results22',\n",
        "    seed=42\n",
        ")\n",
        "#Run the search against the data.)\n",
        "tuner.search(x_train, y_train, epochs=20, validation_data=(x_test, y_test), verbose=1, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "VdJc5iTNl3e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa89ad9-9921-4c10-f6a8-3e1d16794c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 15 Complete [00h 01m 49s]\n",
            "val_accuracy: 0.5976190567016602\n",
            "\n",
            "Best val_accuracy So Far: 0.7869047522544861\n",
            "Total elapsed time: 00h 46m 32s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run model with optimal params\n",
        "tuned_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Best Hyperparameters: {tuned_hps.values}\")\n",
        "tuned_model = tuner.hypermodel.build(tuned_hps)\n",
        "tuned_model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test),callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l7TIrpRDKv3",
        "outputId": "0503394d-94b4-4129-a630-15bcf327a506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'filters_base': 64, 'rate_base': 0.1, 'num_layers': 3, 'F_0': 96, 'R_0': 0.30000000000000004, 'num_dense_layers': 1, 'neurons_0': 192, 'rate_dense_0': 0.2, 'learning_rate': 0.001, 'F_1': 160, 'R_1': 0.1, 'F_2': 224, 'R_2': 0.4, 'neurons_1': 128, 'rate_dense_1': 0.30000000000000004, 'F_3': 192, 'R_3': 0.1}\n",
            "Epoch 1/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.2161 - loss: 0.3364 - val_accuracy: 0.3956 - val_loss: 0.2618\n",
            "Epoch 2/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 17ms/step - accuracy: 0.4048 - loss: 0.2618 - val_accuracy: 0.4599 - val_loss: 0.2368\n",
            "Epoch 3/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.4826 - loss: 0.2367 - val_accuracy: 0.5175 - val_loss: 0.2170\n",
            "Epoch 4/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.5140 - loss: 0.2234 - val_accuracy: 0.5306 - val_loss: 0.2139\n",
            "Epoch 5/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.5542 - loss: 0.2091 - val_accuracy: 0.6028 - val_loss: 0.1946\n",
            "Epoch 6/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.5820 - loss: 0.2009 - val_accuracy: 0.6250 - val_loss: 0.1893\n",
            "Epoch 7/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.5992 - loss: 0.1952 - val_accuracy: 0.6302 - val_loss: 0.1821\n",
            "Epoch 8/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.6283 - loss: 0.1841 - val_accuracy: 0.6714 - val_loss: 0.1702\n",
            "Epoch 9/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.6347 - loss: 0.1809 - val_accuracy: 0.6448 - val_loss: 0.1780\n",
            "Epoch 10/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.6503 - loss: 0.1791 - val_accuracy: 0.6948 - val_loss: 0.1617\n",
            "Epoch 11/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.6731 - loss: 0.1685 - val_accuracy: 0.6885 - val_loss: 0.1657\n",
            "Epoch 12/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7029 - loss: 0.1610 - val_accuracy: 0.7329 - val_loss: 0.1544\n",
            "Epoch 13/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.7084 - loss: 0.1576 - val_accuracy: 0.6873 - val_loss: 0.1614\n",
            "Epoch 14/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7291 - loss: 0.1515 - val_accuracy: 0.7294 - val_loss: 0.1550\n",
            "Epoch 15/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7528 - loss: 0.1457 - val_accuracy: 0.7492 - val_loss: 0.1459\n",
            "Epoch 16/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.7605 - loss: 0.1452 - val_accuracy: 0.7337 - val_loss: 0.1524\n",
            "Epoch 17/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7682 - loss: 0.1427 - val_accuracy: 0.7714 - val_loss: 0.1417\n",
            "Epoch 18/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7829 - loss: 0.1373 - val_accuracy: 0.7758 - val_loss: 0.1408\n",
            "Epoch 19/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.7833 - loss: 0.1370 - val_accuracy: 0.7956 - val_loss: 0.1374\n",
            "Epoch 20/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7944 - loss: 0.1331 - val_accuracy: 0.7881 - val_loss: 0.1378\n",
            "Epoch 21/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7937 - loss: 0.1321 - val_accuracy: 0.7782 - val_loss: 0.1409\n",
            "Epoch 22/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.8044 - loss: 0.1306 - val_accuracy: 0.8067 - val_loss: 0.1334\n",
            "Epoch 23/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8233 - loss: 0.1265 - val_accuracy: 0.7849 - val_loss: 0.1379\n",
            "Epoch 24/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8190 - loss: 0.1264 - val_accuracy: 0.7754 - val_loss: 0.1388\n",
            "Epoch 25/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.8212 - loss: 0.1255 - val_accuracy: 0.8099 - val_loss: 0.1301\n",
            "Epoch 26/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.8379 - loss: 0.1223 - val_accuracy: 0.7992 - val_loss: 0.1331\n",
            "Epoch 27/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8269 - loss: 0.1228 - val_accuracy: 0.8028 - val_loss: 0.1327\n",
            "Epoch 28/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.8440 - loss: 0.1201 - val_accuracy: 0.8008 - val_loss: 0.1353\n",
            "Epoch 29/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8474 - loss: 0.1188 - val_accuracy: 0.8147 - val_loss: 0.1285\n",
            "Epoch 30/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8463 - loss: 0.1193 - val_accuracy: 0.8187 - val_loss: 0.1268\n",
            "Epoch 31/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8557 - loss: 0.1191 - val_accuracy: 0.8119 - val_loss: 0.1302\n",
            "Epoch 32/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8668 - loss: 0.1139 - val_accuracy: 0.8333 - val_loss: 0.1258\n",
            "Epoch 33/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.8691 - loss: 0.1135 - val_accuracy: 0.8135 - val_loss: 0.1294\n",
            "Epoch 34/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8619 - loss: 0.1140 - val_accuracy: 0.8234 - val_loss: 0.1236\n",
            "Epoch 35/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8749 - loss: 0.1107 - val_accuracy: 0.8325 - val_loss: 0.1231\n",
            "Epoch 36/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8703 - loss: 0.1131 - val_accuracy: 0.8127 - val_loss: 0.1304\n",
            "Epoch 37/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8830 - loss: 0.1102 - val_accuracy: 0.8206 - val_loss: 0.1270\n",
            "Epoch 38/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.8777 - loss: 0.1115 - val_accuracy: 0.8143 - val_loss: 0.1282\n",
            "Epoch 39/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8816 - loss: 0.1102 - val_accuracy: 0.8274 - val_loss: 0.1248\n",
            "Epoch 40/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8821 - loss: 0.1090 - val_accuracy: 0.8329 - val_loss: 0.1256\n",
            "Epoch 40: early stopping\n",
            "Restoring model weights from the end of the best epoch: 35.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f1e9433b750>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Show Stats\n",
        "y_pred = tuned_model.predict(x_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "y_test_classes = y_test.argmax(axis=1)\n",
        "\n",
        "overall_accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "\n",
        "report = classification_report(y_test_classes, y_pred_classes, target_names=[f\"Class {i}\" for i in range(7)])\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-lYffixUO4R",
        "outputId": "45cceaba-ec5c-4cce-d99c-ee551d81293c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "Overall Accuracy: 0.8337\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.79      0.72      0.75       360\n",
            "     Class 1       0.77      0.69      0.73       360\n",
            "     Class 2       0.87      0.90      0.88       360\n",
            "     Class 3       0.68      0.79      0.73       360\n",
            "     Class 4       0.94      0.97      0.96       360\n",
            "     Class 5       0.90      0.91      0.90       360\n",
            "     Class 6       0.89      0.85      0.87       360\n",
            "\n",
            "    accuracy                           0.83      2520\n",
            "   macro avg       0.84      0.83      0.83      2520\n",
            "weighted avg       0.84      0.83      0.83      2520\n",
            "\n",
            "Accuracy for Class 0: 0.7167\n",
            "Accuracy for Class 1: 0.6944\n",
            "Accuracy for Class 2: 0.8972\n",
            "Accuracy for Class 3: 0.7944\n",
            "Accuracy for Class 4: 0.9750\n",
            "Accuracy for Class 5: 0.9056\n",
            "Accuracy for Class 6: 0.8528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax Regression model and SVM. Code not covered in the dissertation."
      ],
      "metadata": {
        "id": "me_gO8CdH1h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare the data without 1 hot encoding\n",
        "x_trainml, x_testml, y_trainml, y_testml = train_test_split(X_ready, y_ready, test_size = 0.2, stratify=y_ready, random_state=42)\n",
        "x_train_flat = x_trainml.reshape(x_trainml.shape[0], -1)\n",
        "x_test_flat = x_testml.reshape(x_testml.shape[0], -1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "x_train_scaled = scaler.fit_transform(x_train_flat)\n",
        "x_test_scaled = scaler.transform(x_test_flat)\n"
      ],
      "metadata": {
        "id": "bYoaO4U4QaTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DOES NOT WORK (SVM, MENTIONED IN DISSERTATION EVALUATION)\n",
        "clf = LinearSVC(dual=False,max_iter=1000)\n",
        "clf.fit(x_train_scaled, y_trainml)\n",
        "y_pred_svm = clf.predict(x_test_scaled)"
      ],
      "metadata": {
        "id": "fLuacFiEH5M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DOES NOT WORK (^)\n",
        "predsvm = clf.predict(x_test_scaled)\n",
        "print(classification_report(y_test.argmax(axis=1), predsvm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "VyxhSVAxJ_ip",
        "outputId": "20098c86-36aa-4c77-de92-ce5edbf0bb58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'clf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-875e1aa70389>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredsvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredsvm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the SR model\n",
        "y_train_onehot = to_categorical(y_trainml, num_classes=len(labels))\n",
        "y_test_onehot = to_categorical(y_testml, num_classes=len(labels))\n",
        "\n",
        "lr = Sequential([\n",
        "    Dense(7, activation='softmax', input_shape=(x_train_scaled.shape[1],))\n",
        "])\n",
        "\n",
        "lr.compile(optimizer=Adam(learning_rate=0.01),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "lr.fit(x_train_scaled, y_train_onehot, epochs=50, validation_data=(x_test_scaled, y_test_onehot),callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DaNOvvIGuET",
        "outputId": "9e8042da-7089-40bb-9adc-d1033b329848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.3338 - loss: 45.3985 - val_accuracy: 0.3889 - val_loss: 35.8682\n",
            "Epoch 2/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4515 - loss: 29.7431 - val_accuracy: 0.4659 - val_loss: 30.9939\n",
            "Epoch 3/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4934 - loss: 30.4703 - val_accuracy: 0.4849 - val_loss: 32.1332\n",
            "Epoch 4/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5455 - loss: 24.9936 - val_accuracy: 0.5024 - val_loss: 27.0838\n",
            "Epoch 5/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5676 - loss: 23.8656 - val_accuracy: 0.5202 - val_loss: 28.0364\n",
            "Epoch 6/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5819 - loss: 26.0136 - val_accuracy: 0.4909 - val_loss: 42.4280\n",
            "Epoch 7/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5849 - loss: 28.1947 - val_accuracy: 0.5817 - val_loss: 25.6114\n",
            "Epoch 8/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6558 - loss: 19.7071 - val_accuracy: 0.5536 - val_loss: 31.8122\n",
            "Epoch 9/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6375 - loss: 23.6983 - val_accuracy: 0.5750 - val_loss: 28.5913\n",
            "Epoch 10/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6911 - loss: 16.7229 - val_accuracy: 0.5393 - val_loss: 33.0689\n",
            "Epoch 11/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6984 - loss: 15.6066 - val_accuracy: 0.5675 - val_loss: 34.5925\n",
            "Epoch 12/50\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6970 - loss: 16.5853 - val_accuracy: 0.5964 - val_loss: 30.2724\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f1e3c67c750>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predlr = lr.predict(x_test_scaled)\n",
        "predictions = np.argmax(predlr, axis=1)\n",
        "#Show SR results.\n",
        "print(classification_report(y_testml, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM43VbUjRSoz",
        "outputId": "f1a617a6-e0c0-4c31-c0eb-ca2c44cf4543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.64      0.67       360\n",
            "           1       0.63      0.72      0.67       360\n",
            "           2       0.61      0.47      0.53       360\n",
            "           3       0.65      0.56      0.60       360\n",
            "           4       0.45      0.58      0.51       360\n",
            "           5       0.44      0.37      0.40       360\n",
            "           6       0.62      0.74      0.68       360\n",
            "\n",
            "    accuracy                           0.58      2520\n",
            "   macro avg       0.59      0.58      0.58      2520\n",
            "weighted avg       0.59      0.58      0.58      2520\n",
            "\n"
          ]
        }
      ]
    }
  ]
}