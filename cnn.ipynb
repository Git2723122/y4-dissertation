{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgIr2TAQQdmRSTUE2GnJOW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Git2723122/y4-dissertation/blob/main/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_6CLA1HerHJ",
        "outputId": "d774664c-3076-4258-8649-974b66d1ae5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import normalize, to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras_tuner import RandomSearch"
      ],
      "metadata": {
        "id": "f2cgSqIZker7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], 28, 28 ,1))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28, 28 ,1))\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLszYYLTlZJR",
        "outputId": "c200f2a7-d439-4df2-ac57-eef983f279c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = Sequential([\n",
        "      Conv2D(filters=hp.Int('filters1', 16, 64, step=16), kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
        "      MaxPooling2D((2,2)),\n",
        "      Dropout(rate=hp.Float('rate1',0.1, 0.5, step=0.1)),\n",
        "\n",
        "      Conv2D(filters=hp.Int('filters2', 32, 128, step=32), kernel_size=(3,3), activation='relu',input_shape=(28,28,1)),\n",
        "      MaxPooling2D((2,2)),\n",
        "      Dropout(rate=hp.Float('rate2',0.1,0.5,step=0.1)),\n",
        "\n",
        "      Flatten(),\n",
        "      Dense(units=hp.Int('units',64,256, step=64), activation='relu'),\n",
        "      Dropout(rate=hp.Float('rate3',0.1,0.5,step=0.1)),\n",
        "\n",
        "      Dense(10,activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='tuning',\n",
        "    project_name='tuning'\n",
        ")\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=1, validation_data=(x_test, y_test))\n",
        "\n",
        "tuned_hps = tuner.get_best_hyperparameters(num_trials=3)[0]\n",
        "print(f\"Best Hyperparameters: {tuned_hps.values}\")\n",
        "tuned_model = tuner.hypermodel.build(tuned_hps)\n",
        "tuned_model.fit(x_train, y_train, epochs=2, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "uBOiN0iFkkYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(28,28,1)))\n",
        "  model.add(Conv2D(filters=hp.Int('filters_base', 16, 64, step=16), kernel_size=(3,3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(rate=hp.Float('rate_base', 0.1, 0.5, step=0.1)))\n",
        "\n",
        "  for i in range(hp.Int('num_layers', 1, 3)):\n",
        "    model.add(Conv2D(filters=hp.Int(f'filters_{i}', 32, 128, step=32), kernel_size=(3,3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(rate=hp.Float(f'rate_{i}', 0.1, 0.5, step=0.1)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units=hp.Int('units', 64, 256, step=64), activation='relu'))\n",
        "  model.add(Dropout(rate=hp.Float('rate_dense', 0.1, 0.5, step=0.1)))\n",
        "\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='tuning',\n",
        "    project_name='tuning'\n",
        ")\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=1, validation_data=(x_test, y_test))\n",
        "\n",
        "tuned_hps = tuner.get_best_hyperparameters(num_trials=3)[0]\n",
        "print(f\"Best Hyperparameters: {tuned_hps.values}\")\n",
        "tuned_model = tuner.hypermodel.build(tuned_hps)\n",
        "tuned_model.fit(x_train, y_train, epochs=2, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "VdJc5iTNl3e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f584255-1012-4562-bd92-b0373107c6ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 01s]\n",
            "\n",
            "Best val_accuracy So Far: 0.9610000252723694\n",
            "Total elapsed time: 00h 03m 19s\n",
            "Best Hyperparameters: {'filters_base': 16, 'rate_base': 0.30000000000000004, 'num_layers': 2, 'filters_0': 64, 'rate_0': 0.4, 'units': 192, 'rate_dense': 0.30000000000000004, 'learning_rate': 0.001, 'filters_1': 64, 'rate_1': 0.5, 'filters_2': 32}\n",
            "Epoch 1/2\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 24ms/step - accuracy: 0.6232 - loss: 1.0878 - val_accuracy: 0.9630 - val_loss: 0.1296\n",
            "Epoch 2/2\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 24ms/step - accuracy: 0.9064 - loss: 0.3147 - val_accuracy: 0.9745 - val_loss: 0.0884\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a2d0b312610>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}